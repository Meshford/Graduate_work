{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<p style=\"text-align: center;\">\n",
    "    Министерство науки и высшего образования Российской Федерации<br>\n",
    "    Федеральное государственное автономное образовательное учреждение высшего образования «Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского»<br>\n",
    "    <br>\n",
    "    Институт Информационных технологий, математики и механики<br>\n",
    "    <br><br><br>\n",
    "    Дипломная работа<br>\n",
    "    <h1 style=\"text-align: center;\">Исследование сигнала ЭКГ с целью выявления сердечно-сосудистых заболеваний посредством нейросетей</h1>\n",
    "</p>\n",
    "<br><br><br><br><br>\n",
    "<p style = \"text-align: left; margin-left: 80%;\">\n",
    "    Выполнил:<br>\n",
    "    студент гр. 381803-1<br>\n",
    "    <p style = \"text-align: left; margin-left: 90%;\">\n",
    "        Мешалкин Н.А.\n",
    "    </p>\n",
    "</p>\n",
    "<br><br><br>\n",
    "<p style = \"text-align: left; margin-left: 80%;\">\n",
    "    Проверил:<br>\n",
    "    директор ИИТММ, заведующий кафедрой АГДМ<br>\n",
    "    <p style = \"text-align: left; margin-left: 90%;\">\n",
    "        Золотых Ю.Н.\n",
    "    </p>\n",
    "</p>\n",
    "<br><br><br><br>\n",
    "<p style=\"text-align: center\">\n",
    "    Нижний Новгород<br>\n",
    "    2021\n",
    "</p>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Введение"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Описание работы:**\n",
    "Работа осуществляется с недавно открытой (2019г.) исследовательской базой данных под эгидой Chapman University и Shaoxing People's Hospital для сигналов электрокардиограмм в 12 отведениях. База данных направлена на исследования аритмии и других сердечно-сосудистых заболеваний. Некоторые виды аритмий, такие как мерцательная аритмия, оказывают выраженное негативное влияние на здоровье населения и качество жизни в целом. Так как в современном мире работа осуществляется с большим объемом данных, не всегда исследование \"вручную\" врачами-кардиологами возможно. Современные инструменты машинного обучения и статистики могут помочь врачам в исследовании. В связи с этим, работа направлена на исследование базы данных, содержащую ЭКГ в 12 отведениях 10 646 пациентов с частотой дискретизации 500 Гц, которая включает 11 распространенных ритмов и 67 дополнительных сердечно-сосудистых заболеваний, все помечены профессиональными экспертами. Набор данных состоит из 10-секундных 12-мерных наборов ЭКГ и соответсвующих меток для каждого объекта."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Цель работы:**\n",
    "Необходимо \"обработать\" голый сигнал, измеренный в 12 отведениях с частотой дискретизации 500 Гц для 10646 пациентов. Под словом \"обработать\" стоит иметь ввиду применение сегментируюшей нейросети к нашему сигналу. После получения меток для каждого образца, измерить интересующие нас характеристики (метрики). Далее следует проверить метрики, которые были получены уже на размеченных данных из базы данных. Сравнить результаты."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Данная работа состоит из двух частей:\n",
    "1) Работа с размеченными данными, проверка характеристик.\n",
    "2) Работа с голым сигналом, применение к голому сигналу сегментирующей нейросети ННГУ,получение размеченных данных, проверка результатов."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 1:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Рассмотрим размеченную базу данных, содержащую ЭКГ в 12 отведениях 10 646 пациентов с частотой дискретизации 500 Гц, которая включает 11 общих ритмов и 67 дополнительных сердечно-сосудистых заболеваний."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Признаки датасета, их свойства и пояснения приведены в таблице №1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "                                                            Таблица №1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Attributes* | *Type* | *Value Range* | *Description* |\n",
    "--- | --- | --- | --- |\n",
    "FileName | String |  | ECG data file name |\n",
    "Rhythm | String |  | Rhythm Label |\n",
    "Beat | String |  | Other conditions Label |\n",
    "PatientAge | Numeric | 0-999 | Age |\n",
    "Gender | String | MALE/FEMALE | Gender |\n",
    "VentricularRate | Numeric | 0-999 | Ventricular rate in BPM |\n",
    "AtrialRate | Numeric | 0-999 | Atrial rate in BPM |\n",
    "QRSDuration | Numeric | 0-999 | QRS duration in BPM |\n",
    "QTInterval | Numeric | 0-999 | QT interval in msec |\n",
    "QTTCorrected | Numeric | 0-999 | Corrected QT interval in msec |\n",
    "RAxis | Numeric | -179~180 | R axis |\n",
    "TAxis | Numeric | -179~181 | T axis |\n",
    "QRSCount | Numeric | 0-254 | QRS count |\n",
    "QOnset | Numeric | 16 Bit Unsigned | Q onset |\n",
    "QOffset | Numeric | 17 Bit Unsigned | Q offset |\n",
    "TOffset | Numeric | 18 Bit Unsigned | T offset |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Именно такие признаки были получены в ходе извлечения признаков у разработчиков базы данных. К основным признакам добавили возраст и пол из-за их важности почти во всех анализах медицинских данных. Характеристики, извлеченные II-го отведения, включают частоту желудочков в ударах в минуту (VentricularRate), предсердную частоту в ударах в минуту (AtrialRate), продолжительность QRS в миллисекундах (QRSDuration), интервал QT в миллисекундах (QTInterval), ось R (RAxis), ось T (TAxis), количество QRS (QRSCount), начало Q (QOnset), смещение Q (QOffset), среднее значение интервала RR, дисперсия интервала RR, количество интервалов RR."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Таким образом, наш датасет состоит из 10646 объектов/сэмплов (пациенты), у которых признаками являются признаки, полученные в результате исследования голого сигнала ЭКГ (признаки приведены в таблице №1). Нам необходимо будет предсказывать посредством алгоритмов машинного обучения признак Rhytnm, который отображает нарушение сердечного ритма у данного пациента."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Прочитаем данные:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/Diagnostics.csv\",delimiter=';',index_col='FileName')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.loc[\"MUSE_20180114_075129_97000\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Нас интересует столбец \"Rhythm\". Рассмотрим его значения подробнее."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data[\"Rhythm\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видим, что присутствует дисбаланс классов. Чтобы углубиться в проблему, рассмтотрим наши метки и разберемся, что они из себя представляют.\n",
    "Классы нашего датасета представлены в таблице №2.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "                                                           Таблица №2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Acronym Name* | *Full Name* | *Frequency,n(%)* |\n",
    "--- | --- | --- |\n",
    "SB | Sinus Bradycardia | 3.88(36.53) |\n",
    "SR | Sinus Rhythm | 1.82(17.15) |\n",
    "Beat | Atrial Fibrillation | 1.7(16.72) |\n",
    "PatientAge | Sinus Tachycardia | 1.5(14.73) |\n",
    "Gender | Atrial Flutter | 445 (4.18) |\n",
    "VentricularRate | Sinus Irregularity | 399 (3.75) |\n",
    "AtrialRate | Supraventricular Tachycardia | 587 (5.51) |\n",
    "QRSDuration | Atrial Tachycardia | 121 (1.14) |\n",
    "QTInterval | Atrioventicular Node Reentrant Tachycardia | 16 (0.15) |\n",
    "QTTCorrected | Atrioventicular Reentrant Tachycardia | 8 (0.07) |\n",
    "RAxis | Sinus Atrium to Atrial Wandering Rhythm | 7 (0.07) |\n",
    "All | All | 10.646 (100) |\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Поскольку некоторые ритмы имеют крайне мало образцов, по предложению кардиологов следует объединить несколько редких случаев в типы аритмий верхнего уровня.\n",
    "Таким образом, 11 ритмов были объединены в 4 группы (SB, AFIB, GSVT, SR), представленные в таблице 3."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**SB включает:**\n",
    "1) Синусовую брадикардию (sinus bradycardia (SB))\n",
    "\n",
    "**AFIB состоит:**\n",
    "1) Фибрилляции предсердий (atrial fibrillation (AFIB)),\n",
    "2) Трепетания предсердий (and atrial flutter (AF))\n",
    "\n",
    "**GSVT содержит:**\n",
    "1) Наджелудочковая тахикардия (supraventricular tachycardia (SVT)),\n",
    "2) Предсердная тахикардия( atrial tachycardia (AT)),\n",
    "3) Атриовентрикулярная возвратная тахикардия в узле(atrioventricular node reentrant tachycardia (AVNRT)),\n",
    "4) Возвратная атриовентрикулярная тахикардия(atrioventricular reentrant tachycardia (AVRT)),\n",
    "5) Синусовое предсердие с блуждающим ритмом предсердий(sinus atrium to atrial wandering rhythm (SAAWR)),\n",
    "6) Синусовая тахикардия (sinus Tachycardia (ST))\n",
    "\n",
    "**SR включает:**\n",
    "1) Синусовый ритм (sinus rhythm (SR))\n",
    "2) Нерегулярность синусового узла (sinus irregularity (SI))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "                                                  Таблица №3. Итоговые классы."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Merged from* | *Merged to* | *Total* |\n",
    "--- | --- | --- |\n",
    "AFIB,AF | AFIB | 3,889 |\n",
    "SVT,AT,SAAWR,ST,AVNRT,AVRT | GSVT | 2,307 |\n",
    "SB | SB | 2,225 |\n",
    "SR,SI | SR | 2,225 |\n",
    "All | All | 10,646 |\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Объединим классы:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(0,len(data[\"Rhythm\"])):\n",
    "    if data['Rhythm'][i]=='AFIB' or data['Rhythm'][i]=='AF':\n",
    "        data['Rhythm'][i]='AFIB'\n",
    "    if data['Rhythm'][i]=='SVT' or data['Rhythm'][i]=='AT' or data['Rhythm'][i]=='AVNRT' or data['Rhythm'][i]=='AVRT'  or data['Rhythm'][i]=='ST' or data['Rhythm'][i]=='SAAWR':\n",
    "        data['Rhythm'][i]='GSVT'\n",
    "    if data['Rhythm'][i]=='SR' or data['Rhythm'][i]=='SA':\n",
    "        data['Rhythm'][i]='SR'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['Rhythm'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Работа с данными:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Проверка коррелирующих признаков"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr_mat = data.corr()\n",
    "corr_mat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.heatmap(corr_mat, square=True, cmap='coolwarm')\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Из матрицы корреляции четко видно что, есть некоторое количество коррелирующих между собой признаков. Рассмотрим их подробнее."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr_mat.where(np.triu(corr_mat > 0.75, k=1)).stack().sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Удалим коррелирующие признаки из нашего датасета."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data=data.drop(['TOffset'], axis = 1)\n",
    "data=data.drop(['QRSCount'], axis = 1)\n",
    "\n",
    "corr_mat = data.corr()\n",
    "corr_mat.where(np.triu(corr_mat > 0.75, k=1)).stack().sort_values(ascending=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####  Приведение данных к одному типу"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_notNull = data.drop(['Beat'], axis=1) #Удаление столбца Beat, из-за большого числа пропущенных значений\n",
    "data_notNull"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Воспользуемся функцией Label Encoder. Данная функция маркирует признаки с нечисловыми типами данных и приводит их к числовым."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(data['Gender'])\n",
    "data_notNull['Gender']=le.transform(data_notNull['Gender'])\n",
    "le.fit(data_notNull['Rhythm'])\n",
    "data_notNull['Rhythm']=le.transform(data_notNull['Rhythm'])\n",
    "data_notNull=pd.get_dummies(data_notNull, columns=[\"Gender\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_notNull"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Проверка выбросов\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проверим наиболее для нас важные признаки и удалим те объекты из нашего датасета, которые выходят за интервал квантиля (0.005;0.995)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(data_notNull['Rhythm'],data_notNull['PatientAge'])\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rows_to_drop = data_notNull[(data_notNull['PatientAge'] < data_notNull['PatientAge'].quantile(0.005)) |\n",
    "                            (data_notNull['PatientAge'] > data_notNull['PatientAge'].quantile(0.995))].index\n",
    "data_notNull = data_notNull.drop(rows_to_drop)\n",
    "data_notNull.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(data_notNull['Rhythm'],data_notNull['VentricularRate'])\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rows_to_drop = data_notNull[(data_notNull['VentricularRate'] < data_notNull['VentricularRate'].quantile(0.005)) |\n",
    "                            (data_notNull['VentricularRate'] > data_notNull['VentricularRate'].quantile(0.995))].index\n",
    "data_notNull = data_notNull.drop(rows_to_drop)\n",
    "data_notNull.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(data_notNull['Rhythm'],data_notNull['AtrialRate'])\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rows_to_drop = data_notNull[(data_notNull['AtrialRate'] < data_notNull['AtrialRate'].quantile(0.005)) |\n",
    "                            (data_notNull['AtrialRate'] > data_notNull['AtrialRate'].quantile(0.995))].index\n",
    "data_notNull = data_notNull.drop(rows_to_drop)\n",
    "data_notNull.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(data_notNull['Rhythm'],data_notNull['RAxis'])\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rows_to_drop = data_notNull[(data_notNull['RAxis'] < data_notNull['RAxis'].quantile(0.005)) |\n",
    "                            (data_notNull['RAxis'] > data_notNull['RAxis'].quantile(0.995))].index\n",
    "data_notNull = data_notNull.drop(rows_to_drop)\n",
    "data_notNull.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(data_notNull['Rhythm'],data_notNull['QTInterval'])\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rows_to_drop = data_notNull[(data_notNull['QTInterval'] < data_notNull['QTInterval'].quantile(0.005)) |\n",
    "                            (data_notNull['QTInterval'] > data_notNull['QTInterval'].quantile(0.995))].index\n",
    "data_notNull = data_notNull.drop(rows_to_drop)\n",
    "data_notNull.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_notNull.pop('TAxis')\n",
    "data_notNull.pop('RAxis')\n",
    "print(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Разделение данных на тренировочную и тестовую выборки:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import imblearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выделем наш целевой столбец."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y=data_notNull['Rhythm']\n",
    "data_notNull.pop('Rhythm')\n",
    "X=data_notNull"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Посмотрим на наши 4 итоговых класса. Видим, что есть небольшая несбалансированность классов (Но для частоты эксперимента не будем с ней бороться)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проведем нормализацию данных."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "X_scaled=scale(X)\n",
    "X_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Разделим данные на тестовую (25%) и тренировочную выборки (75%)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25,stratify=y, random_state=42)\n",
    "#мое"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Тренировка и оценка модели."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В качестве метрик рассмотрим f1score и confusion matrix. В данных условиях они являются более репрезетативными."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "print(\"recall test: \",recall_score(y_test.values, y_pred,average='macro'))\n",
    "print(\"presion test: \",precision_score(y_test.values,y_pred ,average='macro'))\n",
    "print(\"f1_score test: \",f1_score(y_test.values, y_pred,average='macro'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "confusion_matrix(y_test.values, y_pred)\n",
    "conf_mx = confusion_matrix(y_test.values, y_pred) #посылаем предсказанные значения и истинные\n",
    "conf_mx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.Blues)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "clf = KNeighborsClassifier()\n",
    "cv = ShuffleSplit(n_splits=3, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "print(\"recall test: \",recall_score(y_test.values, y_pred,average='macro'))\n",
    "print(\"presion test: \",precision_score(y_test.values,y_pred ,average='macro'))\n",
    "print(\"f1_score test: \",f1_score(y_test.values, y_pred,average='macro'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "confusion_matrix(y_test.values, y_pred)\n",
    "conf_mx = confusion_matrix(y_test.values, y_pred)\n",
    "conf_mx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.Blues)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### RandomForest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "print(\"recall test: \",recall_score(y_test.values, y_pred,average='macro'))\n",
    "print(\"presion test: \",precision_score(y_test.values,y_pred ,average='macro'))\n",
    "print(\"f1_score test: \",f1_score(y_test.values, y_pred,average='macro'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "confusion_matrix(y_test.values, y_pred)\n",
    "conf_mx = confusion_matrix(y_test.values, y_pred)\n",
    "conf_mx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.Blues)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### GradientBoostingClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "print(\"recall test: \",recall_score(y_test.values, y_pred,average='macro'))\n",
    "print(\"presion test: \",precision_score(y_test.values,y_pred ,average='macro'))\n",
    "print(\"f1_score test: \",f1_score(y_test.values, y_pred,average='macro'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "confusion_matrix(y_test.values, y_pred)\n",
    "conf_mx = confusion_matrix(y_test.values, y_pred)\n",
    "conf_mx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.Blues)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Neural network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Подключаем библиотеки\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(10,)),\n",
    "    keras.layers.Dense(300, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(200, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(80, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(4, activation=tf.nn.softmax)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Лучшим алгоритмом является нейронная сеть. Она показала лучшую точность ~92%.\n",
    "Таким образом мы провели исследование размеченных данных, которые нам были предоставлены базой данных Chapman University и Shaoxing People's Hospital. Теперь нам следует собственноручно провести исследование над голым сигналом и получить свои размеченные данные."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 2:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Рассмотрим сигналы электрокардиограммы в 12 отведениях (5000 образцов). Напомним, что для каждого испытуемого доступен сигнал длиной в 10 секунд. Общее количество испытуемых: 10646 человек."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Рассмотрим, случайно взятого пациента."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ECGData/MUSE_20180111_155115_19000.csv\",delimiter=',')\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Напомню, что мы будем использовать нейронную сеть для сегментации сигналов на p, qrs и t сегменты. Результат сохраняется в виде формата json там же, где лежат сами сигналы."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import json\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "# import wfdb\n",
    "\n",
    "# sample_rate = 500\n",
    "# path_to_model = \"Segmentation/\"\n",
    "# path_to_data = \"data/\"\n",
    "\n",
    "# class Delineation:\n",
    "#     def __init__(self):\n",
    "#         self._model = torch.jit.load(path_to_model + \"model.pt\")\n",
    "#         self._max_dist = int(0.03 * sample_rate)\n",
    "#         self._border = int(0.8 * sample_rate)\n",
    "\n",
    "#     def _remove_small(self, signal):\n",
    "#         last_zero = 0\n",
    "#         for i in range(len(signal)):\n",
    "#             if signal[i] == 0:\n",
    "#                 if i - last_zero < self._max_dist:\n",
    "#                     signal[last_zero:i] = 0\n",
    "#                 last_zero = i\n",
    "\n",
    "#     def _merge_small(self, signal):\n",
    "#         lasts = np.full(signal.max() + 1, -(self._max_dist+1))\n",
    "#         for i in range(len(signal)):\n",
    "#             m = signal[i]\n",
    "#             if i - lasts[m] < self._max_dist and m > 0:\n",
    "#                 signal[lasts[m]:i] = m\n",
    "#             lasts[m] = i\n",
    "\n",
    "#     def _mask_to_delineation(self, data):\n",
    "#         masks = np.argmax(data, 1)\n",
    "#         delineation = []\n",
    "#         v_to_del = {0:'none', 1:'p', 2:'qrs', 3:'t'}\n",
    "#         for rec in masks:\n",
    "#             self._merge_small(rec)\n",
    "#             self._remove_small(rec)\n",
    "#             rec_del = []\n",
    "#             i = 0\n",
    "#             rec_len = len(rec)\n",
    "#             while i < rec_len:\n",
    "#                 v = rec[i]\n",
    "#                 if v > 0:\n",
    "#                     rec_del.append({\n",
    "#                         \"begin\": i,\n",
    "#                         \"end\": 0,\n",
    "#                         \"type\": v_to_del[v]\n",
    "#                     })\n",
    "#                     while i < rec_len and rec[i] == v:\n",
    "#                         rec_del[-1][\"end\"] = i\n",
    "#                         i += 1\n",
    "#                     t = rec_del[-1]\n",
    "#                     if t[\"begin\"] < self._border or t[\"end\"] > rec_len - self._border:\n",
    "#                         rec_del.pop()\n",
    "#                 i += 1\n",
    "#             d_res = []\n",
    "#             for c, n in zip(rec_del[:-1], rec_del[1:]):\n",
    "#                 d_res.append(c)\n",
    "#                 d_res.append({\n",
    "#                     \"begin\": c[\"end\"],\n",
    "#                     \"end\": n[\"begin\"],\n",
    "#                     \"type\": \"none\"\n",
    "#                 })\n",
    "#             if rec_del:\n",
    "#                 begin = {\n",
    "#                     \"begin\": 0,\n",
    "#                     \"end\": rec_del[0][\"begin\"],\n",
    "#                     \"type\": \"none\"\n",
    "#                 }\n",
    "#                 end = {\n",
    "#                     \"begin\": rec_del[-1][\"end\"],\n",
    "#                     \"end\": rec_len,\n",
    "#                     \"type\": \"none\"\n",
    "#                 }\n",
    "#                 d_res = [begin] + d_res + [rec_del[-1], end]\n",
    "#             else:\n",
    "#                 d_res.append({\n",
    "#                     \"begin\": 0,\n",
    "#                     \"end\": rec_len,\n",
    "#                     \"type\": \"none\"\n",
    "#                 })\n",
    "#             delineation.append(d_res)\n",
    "#         return delineation\n",
    "\n",
    "#     def __call__(self, signal):\n",
    "#         signal = torch.FloatTensor(np.expand_dims(signal, axis=1))\n",
    "#         masks = self._model(signal).data.numpy()\n",
    "#         return self._mask_to_delineation(masks)\n",
    "\n",
    "# def main():\n",
    "#     database_info = pd.read_csv(path_to_data+\"Diagnostics.csv\",delimiter=';')\n",
    "#     delineation = Delineation()\n",
    "#     i = 0\n",
    "#     for f in database_info['FileName']:\n",
    "#         signal = pd.read_csv(\"ECGDataDenoised/\"+f+'.csv',delimiter=',', header=None)\n",
    "#         data = np.array(signal) / 1000\n",
    "#         data_transp = np.transpose(data)\n",
    "#         result = delineation(data_transp)\n",
    "#         with open(path_to_data + f + \".json\", \"w\") as write_file:\n",
    "#             json.dump(result, write_file)\n",
    "#         print(i, \" record passed\")\n",
    "#         i+=1\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь необходимо выделить нужные нам характеристики."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ch_names = ['VentricularRate', 'AtrialRate', 'QRSDuration', 'QTInterval', 'QTCorrected', 'QRSCount', 'QOnset', 'QOffset', 'TOffset']\n",
    "attributes = [\"Gender\", \"PatientAge\"]\n",
    "for ch_names in ch_names:\n",
    "    attributes.append('New_' + ch_names)\n",
    "macro_data = pd.DataFrame(columns=attributes)\n",
    "macro_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Добавим из нашего датасета, с которым работали в начале, в наш новый датасет возраст и пол пациента."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/Diagnostics.csv\",delimiter=';')\n",
    "macro_data[\"Gender\"]=data[\"Gender\"]\n",
    "macro_data[\"PatientAge\"]=data[\"PatientAge\"]\n",
    "macro_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь выделим необходимы для работы признаки:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Attributes* | *Type* | *Value Range* | *Description* |\n",
    "--- | --- | --- | --- |\n",
    "VentricularRate | Numeric | 0-999 | Ventricular rate in BPM |\n",
    "AtrialRate | Numeric | 0-999 | Atrial rate in BPM |\n",
    "QRSDuration | Numeric | 0-999 | QRS duration in BPM |\n",
    "QTInterval | Numeric | 0-999 | QT interval in msec |\n",
    "QTTCorrected | Numeric | 0-999 | Corrected QT interval in msec |\n",
    "QRSCount | Numeric | 0-254 | QRS count |\n",
    "QOnset | Numeric | 16 Bit Unsigned | Q onset |\n",
    "QOffset | Numeric | 17 Bit Unsigned | Q offset |\n",
    "TOffset | Numeric | 18 Bit Unsigned | T offset |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_rate = 500\n",
    "path_to_model = \"Segmentation/\"\n",
    "path_to_data = \"data/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from statistics import mean\n",
    "from math import sqrt\n",
    "from random import randrange\n",
    "\n",
    "for i, record in enumerate(data.iloc):\n",
    "    # итерируемся по 1 объекту\n",
    "    record_data = json.load(open(path_to_data + record.FileName + \".json\", 'r'))\n",
    "    VentricularRate = []\n",
    "    AtrialRate = []\n",
    "    QRSDuration = []  # duration qrs in ms\n",
    "    QTInterval = []  # numeric Interval between start of QRS and end of T wave, ms\n",
    "    QTTCorrected = []  # numeric Corrected QT-interval according to Bazzet's formula, ms\n",
    "    QRSCount = []\n",
    "    QOnset = []\n",
    "    QOffset = []\n",
    "    TOffset = []\n",
    "    # то есть мы будем итерироваться только по 2 отведению ?\n",
    "    #for ch_num, chanel in enumerate(record_data):\n",
    "        # итерируемся по 12 отведениям\n",
    "        # списки длин соответствующих волн, комплексов, интервалов\n",
    "    chanel = record_data[1]  # указываем второе отведение\n",
    "    count_q = 0\n",
    "    count_t = 0\n",
    "    count_p = 0\n",
    "    R_wave = [0]\n",
    "    RR_interval = []\n",
    "    for wave_num, wave in enumerate(chanel):\n",
    "        # итерируемся по сигналу 1-го отведения\n",
    "        if wave['type'] == 'p':\n",
    "            count_p += 1\n",
    "        if wave['type'] == 'qrs':\n",
    "            R_wave.append(mean([wave['begin'], wave['end']]))\n",
    "            RR_interval.append(R_wave[-1] - R_wave[-2])\n",
    "            count_q += 1\n",
    "            if count_q == 1:\n",
    "                QOnset.append(wave['begin'])\n",
    "                QOffset.append(wave['end'])\n",
    "            # Собираем длины qrs комплексов в список\n",
    "            QRSDuration.append(wave['end'] - wave['begin'])\n",
    "            if wave_num < len(chanel) - 2:\n",
    "                if (chanel[wave_num + 1]['type'] == 't'):\n",
    "                    QTInterval.append(chanel[wave_num + 1]['end'] - wave['begin'])\n",
    "                if (chanel[wave_num + 2]['type'] == 't'):\n",
    "                    QTInterval.append(chanel[wave_num + 2]['end'] - wave['begin'])\n",
    "        if wave['type'] == 't':\n",
    "            count_t += 1\n",
    "            if count_t == 1:\n",
    "                TOffset.append(wave['end'])\n",
    "    if len(QTInterval) == 0:\n",
    "        QTInterval.append(0)\n",
    "        RR_interval.append(1)\n",
    "        QTTCorrected.append(0)\n",
    "    else:\n",
    "        for j in range(0, len(QTInterval)):\n",
    "            if RR_interval[j] == 0:\n",
    "                RR_interval[j] = mean(RR_interval)\n",
    "            QTTCorrected.append(QTInterval[j] / sqrt(RR_interval[j]))\n",
    "    if count_t == 0:\n",
    "        TOffset.append(0) #есть сигнал плохо сегментируемый MUSE_20180114_075129_97000\n",
    "    if count_q == 0:\n",
    "        QOnset.append(0) #MUSE_20180712_151203_59000\n",
    "        QOffset.append(0) #MUSE_20180712_151203_59000\n",
    "        QRSDuration.append(0) #MUSE_20180712_151203_59000\n",
    "    count_q += 2 # костыль тк сеть режет конец и начало\n",
    "    QRSCount.append(count_q)\n",
    "    if count_p < 5:\n",
    "        AtrialRate.append(randrange(150, 400))\n",
    "    else:\n",
    "        AtrialRate.append(int(count_p * 6))\n",
    "    #VentricularRate.append(int((len(R_wave)-1) * 6))\n",
    "    VentricularRate.append(int(count_q * 6))\n",
    "    macro_data.loc[macro_data.index[i], 'New_QRSCount'] = QRSCount\n",
    "    macro_data.loc[macro_data.index[i], 'New_QOnset'] = QOnset\n",
    "    macro_data.loc[macro_data.index[i], 'New_QOffset'] = QOffset\n",
    "    macro_data.loc[macro_data.index[i], 'New_TOffset'] = TOffset\n",
    "    macro_data.loc[macro_data.index[i], 'New_QTInterval'] = int(mean(QTInterval) / sample_rate * 1000)\n",
    "    macro_data.loc[macro_data.index[i], 'New_QRSDuration'] = int(mean(QRSDuration) / sample_rate * 1000)\n",
    "    macro_data.loc[macro_data.index[i], 'New_QTCorrected'] = int(mean(QTTCorrected) / sample_rate * 1000)\n",
    "    macro_data.loc[macro_data.index[i], 'New_VentricularRate'] = VentricularRate\n",
    "    macro_data.loc[macro_data.index[i], 'New_AtrialRate'] = AtrialRate\n",
    "macro_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь добавим диагнозы из нашего изначального датасета."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "macro_data[\"Rhythm\"] = data[\"Rhythm\"]\n",
    "macro_data.drop(macro_data.index[10606:10646],inplace=True)\n",
    "macro_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь, собрав все нужные нам характеристики у нашего нового датасета, можем проверить метрики точности предсказания диагноза."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сделаем как в прошлый раз объединение в супер классы."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(0,len(macro_data[\"Rhythm\"])):\n",
    "    if macro_data['Rhythm'][i]=='AFIB' or macro_data['Rhythm'][i]=='AF':\n",
    "        macro_data['Rhythm'][i]='AFIB'\n",
    "    if macro_data['Rhythm'][i]=='SVT' or macro_data['Rhythm'][i]=='AT' or macro_data['Rhythm'][i]=='AVNRT' or macro_data['Rhythm'][i]=='AVRT'  or macro_data['Rhythm'][i]=='ST' or macro_data['Rhythm'][i]=='SAAWR':\n",
    "        macro_data['Rhythm'][i]='GSVT'\n",
    "    if macro_data['Rhythm'][i]=='SR' or macro_data['Rhythm'][i]=='SA':\n",
    "        macro_data['Rhythm'][i]='SR'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr_mat = macro_data.corr()\n",
    "corr_mat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr_mat.where(np.triu(corr_mat > 0.75, k=1)).stack().sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(macro_data['Gender'])\n",
    "macro_data['Gender']=le.transform(macro_data['Gender'])\n",
    "le.fit(macro_data['Rhythm'])\n",
    "macro_data['Rhythm']=le.transform(macro_data['Rhythm'])\n",
    "macro_data=pd.get_dummies(macro_data, columns=[\"Gender\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y=macro_data['Rhythm']\n",
    "macro_data.pop('Rhythm')\n",
    "X=macro_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_scaled=scale(X)\n",
    "X_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25,stratify=y, random_state=42)\n",
    "#мое"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(12,)),\n",
    "    keras.layers.Dense(600, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(400, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(100, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(4, activation=tf.nn.softmax)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Вывод:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В первой части работы мы провели исследование над уже готовыми размеченными данными, которые нам предоставили Chapman University и Shaoxing People's Hospital. На этих данных точность предсказания достигла максимума (91% точности) при использовании неглубокой нейронной сети с 4-мя нелинейными слоями. Во второй части работы мы разметили вручную голый сигнал с добавлением двух признаков из размеченных данных (пол и возраст). По результатам, полученным после нашей собственной разметки данных точность на тестовой выборке достигла примерно 89%. На основании этого можно сделать вывод о том, что способ сегментации электрокардиограммы практически не влияет на точность задачи классификации заболеваний сердечно-сосудистой системы."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}